{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAFA-5 Protein Function Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:28:14.273560Z",
     "iopub.status.busy": "2025-04-06T22:28:14.273278Z",
     "iopub.status.idle": "2025-04-06T22:28:21.761268Z",
     "shell.execute_reply": "2025-04-06T22:28:21.760454Z",
     "shell.execute_reply.started": "2025-04-06T22:28:14.273538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\n",
      "Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12066 sha256=aea487b75f9f7a3c0e39468e757f1f2c1e8e6b5ca81cb8691bcfd3d900184879\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar, biopython\n",
      "Successfully installed biopython-1.85 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython progressbar transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if all our files are uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:28:39.640054Z",
     "iopub.status.busy": "2025-04-06T22:28:39.639674Z",
     "iopub.status.idle": "2025-04-06T22:28:39.646545Z",
     "shell.execute_reply": "2025-04-06T22:28:39.645686Z",
     "shell.execute_reply.started": "2025-04-06T22:28:39.640024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_terms.tsv', 'train_sequences.fasta', 'train_taxonomy.tsv', 'go-basic.obo']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir('/kaggle/input/cafa-5-protein-function-prediction/Train/'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Protein Sequence Loading and Environment Setup\n",
    "\n",
    "This cell performs the following tasks:\n",
    "\n",
    "- **Imports essential libraries** for:\n",
    "  - Deep learning: `torch`\n",
    "  - Data handling: `numpy`, `pandas`\n",
    "  - Biological sequence parsing: `Bio.SeqIO`\n",
    "  - Pre-trained transformer models: `transformers`\n",
    "  - Progress tracking: `progressbar`\n",
    "\n",
    "- **Sets the computation device**:\n",
    "  - Uses GPU (`cuda`) if available, otherwise falls back to CPU.\n",
    "\n",
    "- **Specifies the Protein Language Model**:\n",
    "  - `Rostlab/prot_bert_bfd`, a transformer model trained to understand protein sequences.\n",
    "\n",
    "- **Loads protein sequences** from the `train_sequences.fasta` file:\n",
    "  - Parses the FASTA file using `Bio.SeqIO`.\n",
    "  - Stores the sequences in a dictionary with:\n",
    "    - **Keys**: Protein IDs\n",
    "    - **Values**: Corresponding amino acid sequences\n",
    "\n",
    "This step prepares the dataset for generating embeddings from the pre-trained protein language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:31:22.033409Z",
     "iopub.status.busy": "2025-04-06T22:31:22.032824Z",
     "iopub.status.idle": "2025-04-06T22:31:24.551247Z",
     "shell.execute_reply": "2025-04-06T22:31:24.550453Z",
     "shell.execute_reply.started": "2025-04-06T22:31:22.033380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 142246 protein sequences.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import progressbar\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_NAME = 'Rostlab/prot_bert_bfd'\n",
    "\n",
    "# Load sequences\n",
    "train_fasta_path = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta'\n",
    "sequences = {record.id: str(record.seq) for record in SeqIO.parse(train_fasta_path, 'fasta')}\n",
    "print(f\"Loaded {len(sequences)} protein sequences.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the file paths used to access the training data inside the Kaggle environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:31:29.802727Z",
     "iopub.status.busy": "2025-04-06T22:31:29.802435Z",
     "iopub.status.idle": "2025-04-06T22:31:29.806344Z",
     "shell.execute_reply": "2025-04-06T22:31:29.805487Z",
     "shell.execute_reply.started": "2025-04-06T22:31:29.802706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths (use kaggle's built-in paths)\n",
    "train_fasta_path = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta'\n",
    "train_terms_path = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization & Data Preparation\n",
    "\n",
    "This code defines a custom `ProteinDataset` class to:\n",
    "\n",
    "- Tokenize protein sequences using a pre-trained **Protein Language Model** (ProtBERT).\n",
    "- Format the data for use with a PyTorch `DataLoader`.\n",
    "\n",
    "We then:\n",
    "- Load the tokenizer and model (`ProtBERT`) in half-precision for efficiency.\n",
    "- Create the dataset and batch loader to process sequences in batches of 64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:31:45.272772Z",
     "iopub.status.busy": "2025-04-06T22:31:45.272451Z",
     "iopub.status.idle": "2025-04-06T22:33:10.593122Z",
     "shell.execute_reply": "2025-04-06T22:33:10.591631Z",
     "shell.execute_reply.started": "2025-04-06T22:31:45.272745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, seq_dict, tokenizer, max_len=512):\n",
    "        self.ids = list(seq_dict.keys())\n",
    "        self.sequences = list(seq_dict.values())\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.ids[idx]\n",
    "        sequence = self.sequences[idx]\n",
    "        tokens = self.tokenizer(sequence,\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_len,\n",
    "                                return_tensors='pt')\n",
    "        tokens = {k: v.squeeze(0) for k, v in tokens.items()}\n",
    "        return pid, tokens\n",
    "\n",
    "# Instantiate tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).half().to(device).eval()\n",
    "\n",
    "# Create dataset and loader\n",
    "batch_size = 64  # Adjust if necessary based on GPU\n",
    "dataset = ProteinDataset(sequences, tokenizer, max_len=512)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Protein Embeddings with ProtBERT\n",
    "\n",
    "This block:\n",
    "\n",
    "- Loads the **ProtBERT model** and tokenizer to process protein sequences.\n",
    "- Defines a custom PyTorch `Dataset` for tokenizing sequences and batching them efficiently.\n",
    "- Uses **mean pooling** over the model's last hidden states to create fixed-size embeddings for each protein.\n",
    "- Collects all embeddings in a dictionary and saves them as a CSV file (`protein_embeddings.csv`), ready for downstream tasks like classification or clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T22:37:47.831161Z",
     "iopub.status.busy": "2025-04-06T22:37:47.830788Z",
     "iopub.status.idle": "2025-04-07T01:02:58.747074Z",
     "shell.execute_reply": "2025-04-07T01:02:58.746059Z",
     "shell.execute_reply.started": "2025-04-06T22:37:47.831134Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |############################################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimized embeddings generated and saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'Rostlab/prot_bert_bfd'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).half().to(device)\n",
    "model.eval()\n",
    "\n",
    "max_len = 512  # Reduce length for faster embeddings\n",
    "batch_size = 128  # Set batch size based on your GPU capacity\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, seq_dict, tokenizer, max_len=512):\n",
    "        self.ids = list(seq_dict.keys())\n",
    "        self.sequences = list(seq_dict.values())\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        pid = self.ids[idx]\n",
    "        inputs = self.tokenizer(sequence,\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_len,\n",
    "                                return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        return pid, inputs\n",
    "\n",
    "dataset = ProteinDataset(sequences, tokenizer, max_len=max_len)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = progressbar.ProgressBar(maxval=len(loader)).start()\n",
    "    for idx, (pids, inputs) in enumerate(loader):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).float().cpu().numpy()\n",
    "        embeddings_dict.update(dict(zip(pids, embeddings)))\n",
    "        \n",
    "        bar.update(idx + 1)\n",
    "    bar.finish()\n",
    "\n",
    "embedding_df = pd.DataFrame.from_dict(embeddings_dict, orient='index')\n",
    "embedding_df.index.name = 'Protein Id'\n",
    "embedding_df.reset_index(inplace=True)\n",
    "\n",
    "# Save optimized embeddings\n",
    "embedding_df.to_csv('protein_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T01:09:18.403126Z",
     "iopub.status.busy": "2025-04-07T01:09:18.402747Z",
     "iopub.status.idle": "2025-04-07T01:09:18.439690Z",
     "shell.execute_reply": "2025-04-07T01:09:18.438999Z",
     "shell.execute_reply.started": "2025-04-07T01:09:18.403094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein Id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P20536</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.03302</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.028549</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.128296</td>\n",
       "      <td>-0.130981</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>-0.08667</td>\n",
       "      <td>-0.114502</td>\n",
       "      <td>-0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O73864</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.03302</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.028549</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.128296</td>\n",
       "      <td>-0.130981</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>-0.08667</td>\n",
       "      <td>-0.114502</td>\n",
       "      <td>-0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O95231</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.03302</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.028549</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.128296</td>\n",
       "      <td>-0.130981</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>-0.08667</td>\n",
       "      <td>-0.114502</td>\n",
       "      <td>-0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0B4J1F4</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.03302</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.028549</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.128296</td>\n",
       "      <td>-0.130981</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>-0.08667</td>\n",
       "      <td>-0.114502</td>\n",
       "      <td>-0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P54366</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.03302</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.028549</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.128296</td>\n",
       "      <td>-0.130981</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>-0.08667</td>\n",
       "      <td>-0.114502</td>\n",
       "      <td>-0.013115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein Id         0         1         2        3         4         5  \\\n",
       "0      P20536  0.030762  0.024231  0.136475  0.03302 -0.065308 -0.136108   \n",
       "1      O73864  0.030762  0.024231  0.136475  0.03302 -0.065308 -0.136108   \n",
       "2      O95231  0.030762  0.024231  0.136475  0.03302 -0.065308 -0.136108   \n",
       "3  A0A0B4J1F4  0.030762  0.024231  0.136475  0.03302 -0.065308 -0.136108   \n",
       "4      P54366  0.030762  0.024231  0.136475  0.03302 -0.065308 -0.136108   \n",
       "\n",
       "          6        7         8  ...      1014      1015      1016      1017  \\\n",
       "0 -0.046295  0.03244  0.010941  ...  0.056915 -0.042145 -0.028549  0.025146   \n",
       "1 -0.046295  0.03244  0.010941  ...  0.056915 -0.042145 -0.028549  0.025146   \n",
       "2 -0.046295  0.03244  0.010941  ...  0.056915 -0.042145 -0.028549  0.025146   \n",
       "3 -0.046295  0.03244  0.010941  ...  0.056915 -0.042145 -0.028549  0.025146   \n",
       "4 -0.046295  0.03244  0.010941  ...  0.056915 -0.042145 -0.028549  0.025146   \n",
       "\n",
       "       1018      1019      1020     1021      1022      1023  \n",
       "0 -0.128296 -0.130981  0.026077 -0.08667 -0.114502 -0.013115  \n",
       "1 -0.128296 -0.130981  0.026077 -0.08667 -0.114502 -0.013115  \n",
       "2 -0.128296 -0.130981  0.026077 -0.08667 -0.114502 -0.013115  \n",
       "3 -0.128296 -0.130981  0.026077 -0.08667 -0.114502 -0.013115  \n",
       "4 -0.128296 -0.130981  0.026077 -0.08667 -0.114502 -0.013115  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 5521661,
     "sourceId": 41875,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
